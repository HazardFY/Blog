 淋巴结转移Lymph node metastasis 

问题所在：整张图片过大，硬模拟的存在导致大量的误报 

解决方法：a novel frame-work 充分利用卷积网络进行有效推理，以满足临床实践的速度要求 , 在不同的方法下重建致密预测，以确保准确探测到微和宏观转移 , 结合asynchronous sample prefetching and hard negative mining，可以对网络进行有效的训练 

whole side image WSI存储方式是 多分辨率金字塔结构 , 与多个下采样版本的原始图像 



Metastasis detection(转移检测)的主要问题有：

1. 转移区域(Tumor)和背景的生物structure和texture的较大变化

2.  正常背景细胞具有与转移区域相似的形态学外观 

3. 由于获得(acquosition)过程导致的表现不同

4.  微观和宏观转移瘤的size差异 

5. WSI过大200 000 * 100 000像素

前人经验：

引用27  采用的是取patch的方法会有计算量偏大的问题

 引用30：稀疏的内核技术 在一定程度上缓解效率问题

我们工作的贡献：

1.  我们提出了一个新的框架，称为ScanNet，通过充分利用卷积网络(FCN)的高效推理，以满足临床实践的速度要求，这可以达到几十倍的速度比其他基于patch的方法 

2.  为了进一步提高其性能，我们探索了一种致密的重建机制，以确保微、宏观转移的准确检测。结合asynchronoussample prefetching and hard negative mining策略，可以有效地训练网络 

3.  在Camelyon16基准数据集上的大量实验验证了该方法的有效性。与目前最先进的方法相比，我们的方法在肿瘤定位任务上取得了更快的性能，甚至超过了人类在WSI分类任务上的表现 



首先移除WSI中的无信息部分，随后将处理后的图片导入到FCN网络中，利用简单的形态学操作来细化结果。 



 在详细讨论之前，我们首先从全局的角度来阐述“分而治之”的策略，即，如何将如此庞大的WSI分成roi，然后再将它们输入到ScanNet。然后，我们重点讨论了如何从局部角度克服ROI的细节，包括网络设计和密集重构机制 

 具体来说，分割是在预处理中进行的，ROIs是在后面分别被ScanNet预选和处理的。然后，从ROI派生出的单个概率块缝合在一起，生成如图3(底部)所示的完整预测图。 

 ScanNet本身就属于FCN结构的队列，它相当于一个带输入大小Lf（内部input size）的patch和滑动步长Sf(内部的Scannet的步长)的patch-wise CNN 。 一个patch对应一个预测值，一个patch在WSI上沿一个维度滑动n次，就会产生n+1个预测值，即在此之前，一个大小为Lr= Lf + n∗Sf打印出一个大小为Lp = n +1的概率块。为了确保具有不同偏移量的相邻概率块能够被无缝缝合而不存在间隙和重叠，roi被获取时使用滑动步幅Sr =Sf∗Lp,seeFigure3(b)到(c)。总而言之，这些规则应该满足以下几点 



使用OTSU算法移除多余区域

 与标准的FCNs网络不同，本模型没有upsampling路径 （对分割很重要的但对于detection不是必要的），原因是会降低detection速度，并且能够生产比输入img更小的probability tile.我们随后利用一个重建算法， 通过组装这些小块来产生一个更密集的。 



在一个标准的VGG-16 上实现ScanNet（将最后三层替换为全连接的1024 * 1024 * 2  kernel size 1 * 1）,为了避免FCN预测的边界效应，移除padding操作。基于此修改，我们的ScanNet可以享受从大量自然图像中学习的转移特征[6]，这表明在不进行转移学习的情况下，这些改进是一致的

Train：

Asynchronous Sample Prefetching异步预取样品

解决问题：I/Obottleneck ，当等待输入成批的输入数据的时候GPU空闲

 GPU使用一个消费者进程来消耗训练数据的同时CPU使用多个生产者进程来准备训练样本。  这种策略可以让GPU一直运行，并且在训练阶段至少提高10倍的加速度。 

**Hard Negative Mining**

解决问题;存在大量负样本，与真正的癌细胞转移区分开

为增强区分能力，增加假阳性样本    hardnegativemining(HNM) ，比如说： 从之前训练好的分类器返回到训练数据 

Dense Reconstruction for Accurate Detection

**一种不受FCN内步长约束的生成稠密预测的稠密重建机制** 

网络越深，池化层越多，生成的概率图就越稀疏 . 我们观察到，通过一定的偏移来改变ROI，我们可以捕捉到在FCN内部大步的间隔内丢失的视图，如图4所示 . 我们建议整合这些缺失的视图，以重建一个更密集、更精确的视图。这个过程与插补机制有很大的不同 ,就是滑动窗口呗？